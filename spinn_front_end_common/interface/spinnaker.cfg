# DO NOT EDIT!
# The are the default values
# Edit the cfg in your home directory to change your preferences
# Add / Edit a cfg in the run directory for script specific changes

# Adds to values in PACMAN/pacman/pacman.cfg and SpiNNMan/spinnman/spinnman.cfg
# Which in turn adds to values in SpiNNUtils/spinn_utilities/spinn_utilities.cfg
# and SpiNNMachine/spinn_machine/spinn_machine.cfg

[Reports]
write_energy_report = False
@write_energy_report = Runs the energy reports.
  This includes adding energy monitor cores which will change placements.
  Therefor the default value is not [Info or Debug](Mode)
path_energy_report = energy_report_(n_run).rpt

write_router_reports = Debug
@write_router_reports = Reports the routes used for each partition.
path_router_reports = edge_routing_info.rpt

write_router_summary_report = Debug
@write_router_summary_report = Writes a summary of the routes used per Chip
path_router_summary_report = routing_summary.rpt

write_partitioner_reports = Info
@write_partitioner_reports = Reports how the Application Vertices/ Populations where partitioned into Machine Vertices/ Cores.
path_partitioner_reports = partitioned_by_vertex.rpt

write_application_graph_placer_report = Info
@write_application_graph_placer_report = Writes both placement reports
path_application_graph_placer_report_vertex = placement_by_vertex_using_graph.rpt
@group_path_application_graph_placer_report_vertex = write_application_graph_placer_report
path_application_graph_placer_report_core = placement_by_core_using_graph.rpt
@group_path_application_graph_placer_report_core = write_application_graph_placer_report

write_router_info_report = Info
@write_router_info_report = Write reports showing the keys and masks
path_router_info_report = virtual_key_space_information_report.rpt

write_uncompressed = Debug
@write_uncompressed = Writes the uncompressed routing tables.
path_uncompressed = routing_tables_generated

write_compressed = Debug
@write_compressed = Writes the compressed routing tables.
  Any report for compression may trigger reading these off the machine.
  Compression may only be as far as needed [See]router_table_compress_as_far_as_possible) not as far as possible.
path_compressed = compressed_routing_tables_generated

write_compression_comparison = Debug
@write_compression_comparison = Compares the uncompressed and the compressed routing tables.
  See [write_compressed](write_compressed)
path_compression_comparison = comparison_of_compressed_uncompressed_routing_tables.rpt

write_compression_summary = Debug
@write_compression_summary = Write a summary of the compression done.
  See [write_compressed](write_compressed)
path_compression_summary = compressed_routing_summary.rpt

write_memory_map_report = Debug
@write_memory_map_report = Writes all the memry map reports. the summary and one per Core..
path_memory_map_report_map = memory_map_from_processor_to_address_space
@group_path_memory_map_report_map = write_memory_map_report
path_memory_map_reports = memory_map_reports
@group_path_memory_map_reports = write_memory_map_report

write_network_specification_report = Info
@write_network_specification_report = Write the details of the network.
path_network_specification_report = network_specification.rpt

# provenance goes into the database
read_router_provenance_data = Debug
@read_router_provenance_data = Reads router provenance and writes it into the [database](path_data_database)
read_graph_provenance_data = Debug
@read_graph_provenance_data = Reads graph provenance and writes it into the [database](path_data_database)
read_placements_provenance_data = Debug
@read_placements_provenance_data = Reads placements provenance and writes it into the [database](path_data_database)
read_profile_data = Debug
@read_profile_data = Reads profile provenance and writes it into the [database](path_data_database)
read_provenance_data_on_end = Debug
@read_provenance_data_on_end = Reads provenace data at the end and writes it into the [database](path_data_database)
write_provenance = Info
@write_provenance = Reads other provenance and writes it into the [database](path_data_database)

write_tag_allocation_reports = Debug
@write_tag_allocation_reports = writes both tag reports.
path_tag_allocation_reports_host = tags.rpt
@group_path_tag_allocation_reports_host = write_tag_allocation_reports
path_tag_allocation_reports_machine = tags_on_machine.txt
@group_path_tag_allocation_reports_machine = write_tag_allocation_reports

write_algorithm_timings = Debug
@write_algorithm_timings = Writes a report of the time all algorithms took.
  Note this is a global report which covers all runs even after resets).
  Timings are always saved in the [global provenance database](tpath_global_provenance)
  They may also be [logged](display_algorithm_timings).
tpath_algorithm_timings = algorithm_timings.rpt

write_board_chip_report = Debug
@write_board_chip_report = Writes the reort of the board(s) in use
path_board_chip_report = board_chip_report.txt

write_data_speed_up_reports = Debug
@write_data_speed_up_reports = Runs the reports relating to [data speed up](enable_advanced_monitor_support).
  In small runs advance monitors may not be used even if enabled in which case there will be no report.
path_data_speed_up_reports_speeds = speeds_gained_in_speed_up_process.rpt
@group_path_data_speed_up_reports_speeds = write_data_speed_up_reports
path_data_speed_up_reports_routers = routers_used_in_speed_up_process.rpt
@group_path_data_speed_up_reports_routers = write_data_speed_up_reports

write_sdram_usage_report_per_chip = Info
@write_sdram_usage_report_per_chip = Generates a report on the Sdram usage per Chip and how it was calculated.
path_sdram_usage_report_per_chip = chip_sdram_usage_by_core.rpt

write_json_machine = Debug
@write_json_machine = Write a description of the machine in json format.
  May be [Deleted at the end of the run].(keep_json_files)
path_json_machine = json_files\machine.json

write_json_placements = Debug
@write_json_placements = Writes a description of the placements in json format
  May be [Deleted at the end of the run].(keep_json_files)
path_json_placements = json_files\placements.json

write_json_routing_tables = Debug
@write_json_routing_tables = Writes a description of the routing tables in json format
  May be [Deleted at the end of the run].(keep_json_files)
path_json_routing_tables = json_files\routing_tables.json

keep_json_files = Debug
@keep_json_files = If set False this will delete any json files written at the end of the run.

write_compressor_iobuf = Debug
@write_compressor_iobuf = Reads and writes the commpressor iobuff.
  There will be no iobuf if a host [compressor](compressor) is used or there is [no need to compress](router_table_compress_as_far_as_possible)
  This will be written to [path_iobuf_system](path_iobuf_system)

write_bit_field_compressor_report = Debug
@write_bit_field_compressor_report = writes the bit rield compressor report.
   Run even without bitfield compression.
path_bit_field_compressor_report = bit_field_compressed_summary.rpt

write_drift_report_start = Debug
@group_write_drift_report_start = path_drift_report
write_drift_report_end = Debug
@group_write_drift_report_end = path_drift_report
path_drift_report = clock_drift.csv
@path_drift_report = Reports the clock drift at the start and/or end of the run.
                     Either all Chips or justthe ethernet ones.
drift_report_ethernet_only = True
@group_drift_report_ethernet_only = path_drift_report

write_text_specs = Debug
@write_text_specs = Writes a text version of the dataspecs.
  Note: The [database](path_data_database) is what is actually used for loading the data specs.
path_text_specs = data_spec_text_files

write_fixed_routes_report = Debug
@write_fixed_routes_report = Writes the report for fisxed yours if they are used.
   Unlikely to exist in [enable_advanced_monitor_support](enable_advanced_monitor_support) is False
path_fixed_routes_report = fixed_route_routers

max_reports_kept = 10
@max_reports_kept = The code will attempt to remove old directories in the [Reports Folder](default_report_file_path)
  if they have finished and/or [possibly errored](remove_errored_folders).
  This controls how many are kept.
remove_errored_folders = True
@remove_errored_folders = If True will also [Remove](max_reports_kept) the older error runs.

display_algorithm_timings = True
@display_algorithm_timings = [Logs](instantiate) the time each algorithm took.
   Timings are always saved in the [global provenance database](tpath_global_provenance)
   They may also be [written](write_algorithm_timings) to file.

extract_iobuf = Debug
@extract_iobuf = Reads the iobuf from the cores and saves them dividied by app and system cores.
path_iobuf_app = provenance_data\app_provenance_data
@group_path_iobuf_app = extract_iobuf
path_iobuf_system = provenance_data\system_provenance_data
@group_path_iobuf_system = extract_iobuf
extract_iobuf_from_cores = ALL
@extract_iobuf_from_cores = Effects what [iobuff is extrracted](extract_iobuf).

  legal Values are:
  * All: All cores . Ignores [extract_iobuf_from_binary_types)(extract_iobuf_from_binary_types)
  * None: Use only cores specified by [extract_iobuf_from_binary_types)(extract_iobuf_from_binary_types)
  * Some [Syntax for some chips](down_cores)
extract_iobuf_from_binary_types = None
@extract_iobuf_from_binary_types = Comma seperate list of binary names for cores to extract
clear_iobuf_during_run = True
@clear_iobuf_during_run = At the end of each run the Chip iobuf can be cleared.
  Run after any extraction or if there is no extraction.

provenance_report_cutoff = 20
@provenance_report_cutoff = If provenace is being [written to the database](write_provenance)
  this will liit the amount that will be [Logged](instantiate)

keep_data_database = Info
@keep_data_database = Database file to hold data read back from the machine including [Provenance](write_provenance).
  Always created as used during the run so this setting determines if it kept at the end.
path_data_database = data(reset_str).sqlite3

keep_dataspec_database = Debug
@keep_dataspec_database = Database used to hold the data spec (to be) written to the cores.
  Always created as used during the run so this setting determines if it kept at the end.
path_dataspec_database = ds(reset_str).sqlite3

keep_input_output_database = Info
@keep_input_output_database = live event connection database. Includes metadata.
  Always created as used during the run so this setting determines if it kept at the end.
path_input_output_database = input_output_database.sqlite3

keep_java_log = Debug
@keep_java_log = Log file always created when useing [Java](use_java)
  This determines if it is kept at the end.
path_java_log = jspin.log

keep_stack_trace = Info
@keep_stack_trace = If there is an error this is where the stack trace will be recorded.
  This determines if it is kept at the end.
tpath_stack_trace = stack_trace

tpath_global_provenance = global_provenance.sqlite3
@tpath_global_provenance = The database where provenance is stored.
   There is just one database no matter how many runs or resets are done.
   This database will hold logging [if instantiated](instantiate).
   This will always hold algorthm timing even if not [displayed](display_algorithm_timings) or [written](write_algorithm_timings).

[Machine]
spalloc_port = 22244
@spalloc_port = The port for the [spalloc server](spalloc_server) if used.
spalloc_user = None
@spalloc_user = The user for the [spalloc server](spalloc_server) if used.
   Used if not part of the [URL](spalloc_server).
   If neither provided the environment variable SPALLOC_USERS will be tried.
   The matching password can only come from the [URL](spalloc_server) or the environment variable SPALLOC_PASSWORD.
spalloc_avoid_boards = None
@spalloc_avoid_boards = An (optional) comma seperated list of IP addresses to avoid.
   This is a mainly for temporarily disabling boards that need to be blacklisted/ repaired.

simulation_time_step = 1000
@simulation_time_step = The time step of the simulations in microseconds.
   Ignored if setup is called with a timestep.
time_scale_factor = None
@time_scale_factor = Multiplicative factor to the machine time step
   (does not affect the neuron models accuracy)
   Ignored if setup is called with a time_scale_factor

clear_routing_tables = False
@clear_routing_tables = Clears the routing tables when end is called. Normally not needed.
clear_tags = False
@clear_tags = Clears the routing tables when end is called. Normally not needed.

enable_advanced_monitor_support = True
@enable_advanced_monitor_support = Enables the use of advance monitors.
  This delegate the transfer of data in and out of the machine to specific ocre.
  Highly recommnded unless using a physical board and needing all cores for your simulation to fit.
enable_reinjection = True
@enable_reinjection = Allows for the reinjection of packets if the first send fails.
  Highly recommnded unless testing the transceiver.
disable_advanced_monitor_usage_for_data_in = False
@disable_advanced_monitor_usage_for_data_in = Truns off the usgae of the extra monitors for data in.
  This is now mainly a testing option aa
  the code will automatically disable the extra monitors for small simulations where it is not recommnded.

post_simulation_overrun_before_error = 5
@post_simulation_overrun_before_error = Time in seconds that the simulation will wait for each board to be in the expected state.
   It is highly likely the core has errored after the default time has passed.

[Mapping]
placer = ApplicationPlacer
@placer = Currently only ApplicationPlacer supported.

info_allocator = ZonedRoutingInfoAllocator
@info_allocator = Which Key and mask allocator to use.</br>
  Supported values are:
  * GlobalZonedRoutingInfoAllocator: Recommenned for most cases as produces the best results for compression.
  * ZonedRoutingInfoAllocator: Less optimized so only use if the global one fails.</br></br>

router = ApplicationRouter
@router = Currently only ApplicationRouter supported

routing_table_generator = MergedRoutingTableGenerator
@routing_table_generator = Which algorithm to use to generate the routing tables</br>
  Supported values are:
  * MergedRoutingTableGenerator:  Recommenned as usually produces the best results.
  * BasicRoutingTableGenerator: Less optimized so only use if the merged one fails.</br></br>

precompressor = None
@precompressor = Testing option to add a second compressor before the name one.
   Only supported options are None and Ranged.
   No known case where compression only works with precompression.

compressor = PairOnChipRouterCompression
@compressor = Which algorithm to use to generate the routing tables.</br>
  Supported values are:
  * PairOnChipRouterCompression: Recommended!
     Looks for pairs with the same destination and tries to merge them.
     Make use of the order so late later merges may overlap with earlier ones.
  * PairCompressor: On host/ virtual version
  * PairUnorderedCompressor: Testing Option which does not make use of the order.
  * OrderedCoveringOnChipRouterCompression: Older compressor which attempts to merge all routes with the ame desination at the same time
     Rarely more efficient that the Pair compressor.
     This is currently tested but not supported
  * OrderedCoveringCompressor:
     On host version/ virtual version

  [Compression may not be needed.](router_table_compress_as_far_as_possible)

virtual_compressor = PairCompressor
@virtual_compressor = Which compressor to use when using a [virtual_board](virtual_board)
   As the "OnChip" version will fail!
   See [compressor](compressor) for legal values.
   If None the [compressor](compressor) option is used.

# If True will read compressed routing tables and check them
run_compression_checker = Debug
@run_compression_checker = Runs a check that the compressors worked and repors the results.
   Mainly used for testing changes to the algorithms or bugs.
path_compression_checker = routing_compression_checker_report.rpt

validate_routes_uncompressed = False
@validate_routes_uncompressed = Runs a check that the routing tables are correct before compresssion.
   Mainly used for testing changes to the algorithms or bugs.

validate_json = Debug
@validate_json = Runs schema validation on json files created.
    Mainly used for testing changes to the algorithms or bugs.

[Buffers]
@ = This section control if runs are divided into smaller runs and how.

use_auto_pause_and_resume = True
@use_auto_pause_and_resume = For very long runs (that would run out of memory)
   this will split the run into multiple shorted runs
   with data extraction between them.
   As no affect for runs that do not need this.
minimum_auto_time_steps = 1000
@minimum_auto_time_steps = If using [Auto pause loops](use_auto_pause_and_resume)
   This will guarantee a minimum time of each of the loops.
   This will cause the cause the partititioner to divide the vertex/Population over enough cores.

[Mode]
@ = Semantic sugar for enabling lots of reports at once.

@mode = Mode allow to globally turn on groups of reports.
  * Mode will never turn off a report set to True in the cfg file
  * Only the value from the last cfg file read is used.
    \t* Default file
    \t* Home directory
    \t* Script directory
  * Mode acts after all cfg files have been read
  * The values of mode supported are:
    \t* Production: Does not turn on any cfg options.
      All cfg values of "info" and "debug" will be replaced with False
      This is the recommended value for users not interested in reports.
    \t* Info: Turns on the the most import reports.
      All cfg values of "info" are replaced with True while "debug" will be replaced with False
      This is the recommended value or users interested in the main reports.
    \t* Debug: Turns on all reports except ones which change the Placements
      All cfg values of "info" and "debug" will be replaced with True
      This is the value used by some tests.
    \t* All: Testing option. Likely to be removed.
 * To change what is included in each mode change the values True, Info or Debug
    * Warning changing these values to False may break some tests.
mode = Production

[Database]
create_database = None
@create_database = Testing Option.
  Overrides auto detection if an [Input output database](path_input_output_database) is needed.
wait_on_confirmation = True
@wait_on_confirmation = Testing Option.
    Forces the NotificationProtocol to wait for confirmation when it send messages
wait_on_confirmation_timeout = 10
@wait_on_confirmation_timeout =  Time in seconds for the NotificationProtocol to [wait](wait_on_confirmation).

create_routing_info_to_neuron_id_mapping = True
@create_routing_info_to_neuron_id_mapping = Adds data abuout the routing to the [Input output database](path_input_output_database)
   Recommended to keep on unless you are absoltely sure it is not needed.

[EnergyMonitor]
@ = Setting for the [Energy Monitor](write_energy_report)
sampling_frequency = 10
@sampling_frequency = How often [Energy Monitor](write_energy_report) will sample, in microseconds
n_samples_per_recording_entry = 100
@n_samples_per_recording_entry = The number of smaples taken in each recording of the [Energy Monitor](write_energy_report).

[Java]
@ = This section controls the seetting to active the use of Java

use_java = False
@use_java = Contorls if the sending of the data in and out is delegated to Java.
   Requires additional setup but will be faster especially for jobs using more than one board.
# controlled by use java
path_json_java_placements = json_files\java_placements.json
@path_json_java_placements = Path to the json file with the placement information needed by [Java](use_javaa).

#
java_call = java
@java_call = Call to start a [Java](use_java) process.
    If there is no jdk../bin in your class path this must include the full path

java_spinnaker_path = None
@java_spinnaker_path = Inidrect method to find the jar file for [Java](use_java) to run.
    Absolute path to where the JavaSpiNNaker git repository is located.
    This must point to a local copy of
    https://github.com/SpiNNakerManchester/JavaSpiNNaker
    It must also have been built!
    If none it will be assumed to be in the same parent directory as SpiNNFrontEndCommon
    Note: Do not quote even if path has spaces as these added by subprocess.call

# Absolute path to where the spinnaker-exe.jar is located.
# Get this from the latest release at https://github.com/SpiNNakerManchester/JavaSpiNNaker
# Only use this if you have not built JavaSpiNNaker
java_jar_path = None
@java_jar_path = Indirect method to find the jar file for [Java](use_java) to run.
   Should only be used if [java_spinnaker_path](java_spinnaker_path) and its default can not be used

java_properties = None
@java_properties = Properties flag to be passed into every Java call.
   Unlikely to be needed unless Testing or debugging.

   Default logging level is info so NO properties needed

   Each Property must start with the -D flag
   To turn on debug level logging (lots)
   java_properties=-Dlogging.level=DEBUG

   Multiple properties are supported.
   Properties must be separated with a space and without quotes.
   ex: java_properties=-Dspinnaker.compare.download -Dlogging.level=DEBUG

   Supported properties are:
   * spinnaker.compare.download:  enables comparisons of multiple download methods; slow
   * spinnaker.parallel_tasks:    how many downloads to do in parallel; default: 4
   * logging.level:  defaults to INFO; DEBUG is also useful
   * logging.udp    enables low-level logging of UDP traffic; produces a lot of output
   * spinnaker.scp_timeout       how long to wait for SCP replies from
     SpiNNaker, in milliseconds, which may need to
     be raised on very busy networks; default: 1000
